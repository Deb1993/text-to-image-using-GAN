{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pdb\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pdb\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Text2ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datasetFile, transform=None, split=0):\n",
    "        self.datasetFile = datasetFile\n",
    "        self.transform = transform\n",
    "        self.dataset = None\n",
    "        self.dataset_keys = None\n",
    "        self.split = 'train' if split == 0 else 'valid' if split == 1 else 'test'\n",
    "        self.h5py2int = lambda x: int(np.array(x))\n",
    "\n",
    "    def __len__(self):\n",
    "        f = h5py.File(self.datasetFile, 'r')\n",
    "        self.dataset_keys = [str(k) for k in f[self.split].keys()]\n",
    "        length = len(f[self.split])\n",
    "        f.close()\n",
    "\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset is None:\n",
    "            self.dataset = h5py.File(self.datasetFile, mode='rb')\n",
    "            self.dataset_keys = [str(k) for k in self.dataset[self.split].keys()]\n",
    "\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "\n",
    "        # pdb.set_trace()\n",

    "        #print \"image = \", len(example)\n",
    "        right_image = np.array(example['img']).tobytes()\n",
    "        right_embed = np.array(example['embeddings'], dtype=float)\n",
    "        wrong_image = np.array(self.find_wrong_image(example['class'])).tobytes()\n",
=======
    "\n",
    "        right_image = np.array(example['img'])\n",
    "        right_embed = np.array(example['embeddings'], dtype=float)\n",
    "        wrong_image = np.array(self.find_wrong_image(example['class']))\n",

    "        inter_embed = np.array(self.find_inter_embed())\n",
    "\n",
    "        right_image = Image.open(io.BytesIO(right_image)).resize((64, 64))\n",
    "        wrong_image = Image.open(io.BytesIO(wrong_image)).resize((64, 64))\n",
    "\n",
    "        right_image = self.validate_image(right_image)\n",
    "        wrong_image = self.validate_image(wrong_image)\n",
    "\n",
    "        txt = np.array(example['txt']).astype(str)\n",
    "\n",
    "        sample = {\n",
    "                'right_images': torch.FloatTensor(right_image),\n",
    "                'right_embed': torch.FloatTensor(right_embed),\n",
    "                'wrong_images': torch.FloatTensor(wrong_image),\n",
    "                'inter_embed': torch.FloatTensor(inter_embed),\n",
    "                'txt': str(txt)\n",
    "                 }\n",
    "\n",
    "        sample['right_images'] = sample['right_images'].sub_(127.5).div_(127.5)\n",
    "        sample['wrong_images'] =sample['wrong_images'].sub_(127.5).div_(127.5)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def find_wrong_image(self, category):\n",
    "        idx = np.random.randint(len(self.dataset_keys))\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "        _category = example['class']\n",
    "\n",
    "        if _category != category:\n",
    "            return example['img']\n",
    "\n",
    "        return self.find_wrong_image(category)\n",
    "\n",
    "    def find_inter_embed(self):\n",
    "        idx = np.random.randint(len(self.dataset_keys))\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "        return example['embeddings']\n",
    "\n",
    "\n",
    "    def validate_image(self, img):\n",
    "        img = np.array(img, dtype=float)\n",
    "        if len(img.shape) < 3:\n",
    "            rgb = np.empty((64, 64, 3), dtype=np.float32)\n",
    "            rgb[:, :, 0] = img\n",
    "            rgb[:, :, 1] = img\n",
    "            rgb[:, :, 2] = img\n",
    "            img = rgb\n",
    "\n",
    "        return img.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
