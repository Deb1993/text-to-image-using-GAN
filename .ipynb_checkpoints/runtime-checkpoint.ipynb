{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/datasets/home/23/223/rmanandi/text-to-image-using-GAN/\")\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> dfc2330e28b5400122771cf6bac21c7dee5d587b
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from trainer import Trainer     #trainer.ipynb file\n",
    "import trainer\n",
    "import argparse\n",
    "from PIL import Image   #This may not be used\n",
    "import os    ##This may not be used\n",
    "import easydict\n",
    "import io"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer     #trainer.ipynb file"
>>>>>>> dfc2330e28b5400122771cf6bac21c7dee5d587b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"visdom\"\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"txt2image_dataset.ipynb\", line 35, in __getitem__\n    \"outputs\": [],\n  File \"/opt/conda/lib/python2.7/site-packages/PIL/Image.py\", line 2585, in open\n    % (filename if filename else fp))\nIOError: cannot identify image file <_io.BytesIO object at 0x7f11015ad050>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7712cf093966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/56/156/aboghani/text-to-image-using-GAN/trainer.ipynb\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;34m\"            self.discriminator.apply(utils.Utils.weights_init)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;34m\"        if pre_trained_gen:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;34m\"            self.generator.load_state_dict(torch.load(pre_trained_gen))\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;34m\"        else:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/56/156/aboghani/text-to-image-using-GAN/trainer.ipynb\u001b[0m in \u001b[0;36m_train_gan\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m\"                    d_loss = real_loss - fake_loss\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;34m\"                    if cls:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m\"                        d_loss = d_loss - wrong_loss\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/conda/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"txt2image_dataset.ipynb\", line 35, in __getitem__\n    \"outputs\": [],\n  File \"/opt/conda/lib/python2.7/site-packages/PIL/Image.py\", line 2585, in open\n    % (filename if filename else fp))\nIOError: cannot identify image file <_io.BytesIO object at 0x7f11015ad050>\n"
     ]
    }
   ],
   "source": [
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from PIL import Image   #This may not be used\n",
    "import os    ##This may not be used\n",
    "import easydict\n",
    "\n",
>>>>>>> dfc2330e28b5400122771cf6bac21c7dee5d587b
    "args = easydict.EasyDict({'type': 'gan', \n",
    "                         'lr': 0.0002,\n",
    "                         'l1_coef': 50,\n",
    "                         'l2_coef': 100,\n",
    "                         'diter': 5,\n",
    "                         'cls': False,\n",
    "                         'vis_screen': 'gan',\n",
    "                         'save_path':'',\n",
    "\n",
    "'inference': False,\n",
    "'pre_trained_disc': None,\n",
    "'pre_trained_gen': None,\n",
    "'dataset': 'flowers', \n",
    "'split': 0,\n",
    "'batch_size':64,\n",
    "'num_workers':8,\n",
    "'epochs':200})\n",
    "\n",
<<<<<<< HEAD
    "trainer = trainer.Trainer(type=args.type,\n",
=======
    "trainer = Trainer(type=args.type,\n",
>>>>>>> dfc2330e28b5400122771cf6bac21c7dee5d587b
    "                  dataset=args.dataset,\n",
    "                  split=args.split,\n",
    "                  lr=args.lr,\n",
    "                  diter=args.diter,   #This may not be used \n",
    "                  vis_screen=args.vis_screen,\n",
    "                  save_path=args.save_path,\n",
    "                  l1_coef=args.l1_coef,\n",
    "                  l2_coef=args.l2_coef,\n",
    "                  pre_trained_disc=args.pre_trained_disc,\n",
    "                  pre_trained_gen=args.pre_trained_gen,\n",
    "                  batch_size=args.batch_size,\n",
    "                  num_workers=args.num_workers,\n",
    "                  epochs=args.epochs\n",
    "                  )\n",
    "\n",
    "if not args.inference:\n",
    "    trainer.train(args.cls)\n",
    "else:\n",
    "    trainer.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> dfc2330e28b5400122771cf6bac21c7dee5d587b
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
